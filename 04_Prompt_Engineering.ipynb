{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bc3cd89-452e-4f49-a776-98710f1f45f5",
   "metadata": {},
   "source": [
    "# Zero-Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "015e4e57-89e2-401f-b9fa-cdf4e2bd309b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50c90de5-dd44-43d6-ab30-c0352a85b0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a82a1a6-6eba-48ab-959a-80efb4922550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'Ollama is running'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.get(\"http://localhost:11434\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42759576-6d9e-40d8-adfd-7a58aac45750",
   "metadata": {},
   "outputs": [],
   "source": [
    "OLLAMA_BASE_URL = \"http://localhost:11434/v1\"\n",
    "\n",
    "ollama = OpenAI(base_url=OLLAMA_BASE_URL, api_key='ollama')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04a20ba0-3c70-4a44-a734-d945fd070947",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"llama3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eae704e4-c5eb-470d-9c4e-4fb4de781d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_ollama import ChatOllama\n",
    "#from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_classic.chains import ConversationChain\n",
    "from langchain_classic.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f6b9c52e-b0bb-4fac-83d4-80b988670c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Ollama model\n",
    "llm = ChatOllama(\n",
    "    model=model_name,   # change to mistral / qwen2.5 if you want\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "def create_chain(prompt_template: str):\n",
    "    \"\"\"\n",
    "    Create a LangChain runnable chain with the given prompt template.\n",
    "\n",
    "    Args:\n",
    "        prompt_template (str): The prompt template string.\n",
    "\n",
    "    Returns:\n",
    "        Runnable: A LangChain runnable sequence.\n",
    "    \"\"\"\n",
    "    prompt = PromptTemplate.from_template(prompt_template)\n",
    "    return prompt | llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e1cdfb-e169-4ba4-9f27-66a40ff5b47c",
   "metadata": {},
   "source": [
    "## Direct Task Specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "670c3a53-3451-4f9b-bc74-ecd95f1748da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: I absolutely loved the movie! The acting was superb.\n",
      "Sentiment: Positive\n",
      "Text: The weather today is quite typical for this time of year.\n",
      "Sentiment: Neutral.\n",
      "Text: I'm disappointed with the service I received at the restaurant.\n",
      "Sentiment: Negative\n"
     ]
    }
   ],
   "source": [
    "direct_task_prompt = \"\"\"Classify the sentiment of the following text as positive, negative, or neutral.\n",
    "Do not explain your reasoning, just provide the classification.\n",
    "\n",
    "Text: {text}\n",
    "\n",
    "Sentiment:\"\"\"\n",
    "\n",
    "direct_task_chain = create_chain(direct_task_prompt)\n",
    "\n",
    "# Test the direct task specification\n",
    "texts = [\n",
    "    \"I absolutely loved the movie! The acting was superb.\",\n",
    "    \"The weather today is quite typical for this time of year.\",\n",
    "    \"I'm disappointed with the service I received at the restaurant.\"\n",
    "]\n",
    "\n",
    "for text in texts:\n",
    "    result = direct_task_chain.invoke({\"text\": text}).content\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Sentiment: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395ba283-b48a-4685-be4b-2e6885efe3db",
   "metadata": {},
   "source": [
    "## Format Specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bf6ce19e-ae58-415a-89bd-00d4c51890d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Headline:** \"Earth's Cousin Discovered: Scientists Stunned by New Exoplanet Find\"\n",
      "\n",
      "**Lead:** In a groundbreaking discovery that has sent shockwaves through the scientific community, astronomers have identified a new exoplanet that bears striking similarities to Earth. The planet, dubbed \"Nyx-12,\" is located approximately 100 light-years from our solar system and boasts a surface temperature that could potentially support liquid water, a crucial ingredient for life.\n",
      "\n",
      "**Body:** According to researchers at the European Southern Observatory (ESO), Nyx-12 orbits a stable G-type star, similar to the Sun, which suggests that it may have a habitable zone where conditions are suitable for life. The exoplanet's size and mass are also comparable to those of Earth, further fueling speculation about its potential for supporting life. Initial observations indicate that Nyx-12 has a thick atmosphere, with hints of oxygen and methane, which could be indicative of biological activity.\n",
      "\n",
      "**Conclusion:** As news of the discovery spreads, scientists are eagerly awaiting further data and analysis to confirm whether Nyx-12 is indeed an Earth-like exoplanet worthy of further study. With this breakthrough, the search for extraterrestrial life has taken a significant step forward, leaving us with more questions than answers about our place in the universe.\n"
     ]
    }
   ],
   "source": [
    "format_spec_prompt = \"\"\"Generate a short news article about {topic}. \n",
    "Structure your response in the following format:\n",
    "\n",
    "Headline: [A catchy headline for the article]\n",
    "\n",
    "Lead: [A brief introductory paragraph summarizing the key points]\n",
    "\n",
    "Body: [2-3 short paragraphs providing more details]\n",
    "\n",
    "Conclusion: [A concluding sentence or call to action]\"\"\"\n",
    "\n",
    "format_spec_chain = create_chain(format_spec_prompt)\n",
    "\n",
    "# Test the format specification prompting\n",
    "topic = \"The discovery of a new earth-like exoplanet\"\n",
    "result = format_spec_chain.invoke({\"topic\": topic}).content\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81277f03-1c2d-4f23-9b94-858e4fcd7166",
   "metadata": {},
   "source": [
    "## Multi-Step Reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b6bd0e58-7525-4071-b87b-5a165621993b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's the analysis of the text:\n",
      "\n",
      "**1. Main Argument:**\n",
      "The primary claim or thesis of the text is that electric vehicles (EVs) are not as environmentally friendly as they seem, and their impact on climate change is more complex than often touted.\n",
      "\n",
      "**2. Supporting Evidence:**\n",
      "\n",
      "* The production of batteries for EVs requires significant mining operations, leading to habitat destruction and water pollution.\n",
      "* If the electricity used to charge EVs comes from fossil fuel sources, the overall carbon footprint may not be significantly reduced.\n",
      "* However, as renewable energy sources become more prevalent and battery technology improves, EVs could play a crucial role in combating climate change.\n",
      "\n",
      "**3. Potential Counterarguments:**\n",
      "\n",
      "* One possible counterargument is that while mining operations for battery production can have negative environmental impacts, these can be mitigated through responsible sourcing practices, recycling, and closed-loop production methods.\n",
      "* Another potential counterargument is that even if the electricity used to charge EVs comes from fossil fuel sources, the overall carbon footprint of EVs may still be lower than traditional gasoline-powered vehicles due to the efficiency gains in electric motors and reduced energy consumption during charging.\n",
      "* Some might argue that the benefits of EVs, such as reduced greenhouse gas emissions and improved air quality, outweigh the potential drawbacks, especially if renewable energy sources become more widespread.\n",
      "* Additionally, some critics might point out that the production of EVs requires significant amounts of resources, including rare earth metals and other materials, which could lead to environmental degradation and social concerns in mining communities.\n",
      "\n",
      "Overall, the text presents a nuanced view of the environmental impact of electric vehicles, highlighting both the potential benefits and drawbacks.\n"
     ]
    }
   ],
   "source": [
    "multi_step_prompt = \"\"\"Analyze the following text for its main argument, supporting evidence, and potential counterarguments. \n",
    "Provide your analysis in the following steps:\n",
    "\n",
    "1. Main Argument: Identify and state the primary claim or thesis.\n",
    "2. Supporting Evidence: List the key points or evidence used to support the main argument.\n",
    "3. Potential Counterarguments: Suggest possible objections or alternative viewpoints to the main argument.\n",
    "\n",
    "Text: {text}\n",
    "\n",
    "Analysis:\"\"\"\n",
    "\n",
    "multi_step_chain = create_chain(multi_step_prompt)\n",
    "\n",
    "# Test the multi-step reasoning approach\n",
    "text = \"\"\"While electric vehicles are often touted as a solution to climate change, their environmental impact is not as straightforward as it seems. \n",
    "The production of batteries for electric cars requires significant mining operations, which can lead to habitat destruction and water pollution. \n",
    "Moreover, if the electricity used to charge these vehicles comes from fossil fuel sources, the overall carbon footprint may not be significantly reduced. \n",
    "However, as renewable energy sources become more prevalent and battery technology improves, electric vehicles could indeed play a crucial role in combating climate change.\"\"\"\n",
    "\n",
    "result = multi_step_chain.invoke({\"text\": text}).content\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9fd788-5bfb-4f21-8da5-f1db2e67bfae",
   "metadata": {},
   "source": [
    "## Comparative Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "908df130-334c-41f6-9415-da4f568e5a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: Explain concisely the concept of blockchain technology\n",
      "\n",
      "Basic Prompt Result:\n",
      "Blockchain technology is a decentralized, digital ledger that records transactions across a network of computers in a secure and transparent manner. It uses cryptography to ensure the integrity and immutability of data, allowing for:\n",
      "\n",
      "1. Secure storage: Data is stored on multiple nodes, making it difficult to manipulate or alter.\n",
      "2. Transparency: All transactions are recorded publicly, providing a clear history of activity.\n",
      "3. Consensus: Nodes agree on the state of the blockchain through complex algorithms.\n",
      "\n",
      "This creates a tamper-proof and decentralized system for storing and sharing data, enabling applications such as cryptocurrency, supply chain management, and identity verification.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Structured Prompt Result:\n",
      "Here's a concise explanation of blockchain technology:\n",
      "\n",
      "**Definition:** Blockchain is a decentralized, digital ledger that records transactions across a network of computers in a secure and transparent manner.\n",
      "\n",
      "**Key Features:**\n",
      "\n",
      "1. **Decentralized**: No single entity controls the network.\n",
      "2. **Immutable**: Transactions are recorded in a permanent, unalterable format.\n",
      "3. **Consensus mechanism**: Nodes on the network verify and agree on transactions.\n",
      "4. **Cryptography**: Secure communication and data protection.\n",
      "\n",
      "**Real-world Applications:**\n",
      "\n",
      "1. **Cryptocurrencies**: Bitcoin, Ethereum, etc.\n",
      "2. **Supply chain management**: Tracking goods and inventory.\n",
      "3. **Smart contracts**: Self-executing contracts with automated rules.\n",
      "4. **Identity verification**: Secure storage of personal data.\n",
      "5. **Healthcare**: Secure sharing of medical records.\n",
      "\n",
      "**Potential Impact on Industries:**\n",
      "\n",
      "1. **Finance**: Increased security, efficiency, and transparency in transactions.\n",
      "2. **Supply chain management**: Improved tracking and reduced counterfeiting.\n",
      "3. **Healthcare**: Enhanced patient data security and access control.\n",
      "4. **Voting systems**: Secure and transparent voting processes.\n",
      "5. **Cybersecurity**: Improved protection against data breaches and cyber attacks.\n",
      "\n",
      "Overall, blockchain technology has the potential to transform various industries by providing a secure, transparent, and efficient way to record and verify transactions.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def compare_prompts(task, prompt_templates):\n",
    "    \"\"\"\n",
    "    Compare different prompt templates for the same task.\n",
    "    \n",
    "    Args:\n",
    "        task (str): The task description or input.\n",
    "        prompt_templates (dict): A dictionary of prompt templates with their names as keys.\n",
    "    \"\"\"\n",
    "    print(f\"Task: {task}\\n\")\n",
    "    for name, template in prompt_templates.items():\n",
    "        chain = create_chain(template)\n",
    "        result = chain.invoke({\"task\": task}).content\n",
    "        print(f\"{name} Prompt Result:\")\n",
    "        print(result)\n",
    "        print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "\n",
    "task = \"Explain concisely the concept of blockchain technology\"\n",
    "\n",
    "prompt_templates = {\n",
    "    \"Basic\": \"Explain {task}.\",\n",
    "    \"Structured\": \"\"\"Explain {task} by addressing the following points:\n",
    "1. Definition\n",
    "2. Key features\n",
    "3. Real-world applications\n",
    "4. Potential impact on industries\"\"\"\n",
    "}\n",
    "\n",
    "compare_prompts(task, prompt_templates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566bdaf1-4dc7-48cb-9ec4-102254dc5ae4",
   "metadata": {},
   "source": [
    "# Few-Shot Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9bd0ca9c-5b93-4d4b-b4e1-6bd2b1008795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: I can't believe how great this new restaurant is!\n",
      "Predicted Sentiment: Positive\n"
     ]
    }
   ],
   "source": [
    "def few_shot_sentiment_classification(input_text):\n",
    "    few_shot_prompt = PromptTemplate(\n",
    "        input_variables=[\"input_text\"],\n",
    "        template=\"\"\"\n",
    "        Classify the sentiment as Positive, Negative, or Neutral.\n",
    "        \n",
    "        Examples:\n",
    "        Text: I love this product! It's amazing.\n",
    "        Sentiment: Positive\n",
    "        \n",
    "        Text: This movie was terrible. I hated it.\n",
    "        Sentiment: Negative\n",
    "        \n",
    "        Text: The weather today is okay.\n",
    "        Sentiment: Neutral\n",
    "        \n",
    "        Now, classify the following:\n",
    "        Text: {input_text}\n",
    "        Sentiment:\n",
    "        \"\"\"\n",
    "    )\n",
    "    \n",
    "    chain = few_shot_prompt | llm\n",
    "    result = chain.invoke(input_text).content\n",
    "\n",
    "    # Clean up the result\n",
    "    result = result.strip()\n",
    "    # Extract only the sentiment label\n",
    "    if ':' in result:\n",
    "        result = result.split(':')[1].strip()\n",
    "    \n",
    "    return result  # This will now return just \"Positive\", \"Negative\", or \"Neutral\"\n",
    "\n",
    "test_text = \"I can't believe how great this new restaurant is!\"\n",
    "result = few_shot_sentiment_classification(test_text)\n",
    "print(f\"Input: {test_text}\")\n",
    "print(f\"Predicted Sentiment: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a51fba98-de03-4932-8cac-3f2465d2ec59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentiment of the text \"I can't believe how great this is!\" is Positive.\n",
      "The text \"Guten Tag, wie geht es Ihnen?\" is in German.\n"
     ]
    }
   ],
   "source": [
    "def multi_task_few_shot(input_text, task):\n",
    "    few_shot_prompt = PromptTemplate(\n",
    "        input_variables=[\"input_text\", \"task\"],\n",
    "        template=\"\"\"\n",
    "        Perform the specified task on the given text.\n",
    "        \n",
    "        Examples:\n",
    "        Text: I love this product! It's amazing.\n",
    "        Task: sentiment\n",
    "        Result: Positive\n",
    "        \n",
    "        Text: Bonjour, comment allez-vous?\n",
    "        Task: language\n",
    "        Result: French\n",
    "        \n",
    "        Now, perform the following task:\n",
    "        Text: {input_text}\n",
    "        Task: {task}\n",
    "        Result:\n",
    "        \"\"\"\n",
    "    )\n",
    "    \n",
    "    chain = few_shot_prompt | llm\n",
    "    return chain.invoke({\"input_text\": input_text, \"task\": task}).content\n",
    "\n",
    "print(multi_task_few_shot(\"I can't believe how great this is!\", \"sentiment\"))\n",
    "print(multi_task_few_shot(\"Guten Tag, wie geht es Ihnen?\", \"language\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e6295c-7d39-4cc8-8be8-82e4c56a6762",
   "metadata": {},
   "source": [
    "## In-Context Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8e34fb23-d9b6-4dec-ad4b-a9b780684b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: python\n",
      "Output: def convert_to_pig_latin(word):\n",
      "    if word[0] in 'aeiou':\n",
      "        return word + 'y'\n",
      "    else:\n",
      "        return word[1:] + word[0] + 'ay'\n",
      "\n",
      "print(convert_to_pig_latin('python'))  # Output: ythonpay\n"
     ]
    }
   ],
   "source": [
    "def in_context_learning(task_description, examples, input_text):\n",
    "    example_text = \"\".join([f\"Input: {e['input']}\\nOutput: {e['output']}\\n\\n\" for e in examples])\n",
    "    \n",
    "    in_context_prompt = PromptTemplate(\n",
    "        input_variables=[\"task_description\", \"examples\", \"input_text\"],\n",
    "        template=\"\"\"\n",
    "        Task: {task_description}\n",
    "        \n",
    "        Examples:\n",
    "        {examples}\n",
    "        \n",
    "        Now, perform the task on the following input:\n",
    "        Input: {input_text}\n",
    "        Output:\n",
    "        \"\"\"\n",
    "    )\n",
    "    \n",
    "    chain = in_context_prompt | llm\n",
    "    return chain.invoke({\"task_description\": task_description, \"examples\": example_text, \"input_text\": input_text}).content\n",
    "\n",
    "task_desc = \"Convert the given text to pig latin.\"\n",
    "examples = [\n",
    "    {\"input\": \"hello\", \"output\": \"ellohay\"},\n",
    "    {\"input\": \"apple\", \"output\": \"appleay\"}\n",
    "]\n",
    "test_input = \"python\"\n",
    "\n",
    "result = in_context_learning(task_desc, examples, test_input)\n",
    "print(f\"Input: {test_input}\")\n",
    "print(f\"Output: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c86e4cf-d197-422f-b845-08aba24db64a",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3452e57a-ff98-4d4b-9a7d-8f789f01cbc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: This product exceeded my expectations!\n",
      "Predicted: Positive\n",
      "Actual: Positive\n",
      "Correct: True\n",
      "\n",
      "Input: I'm utterly disappointed with the service.\n",
      "Predicted: Negative\n",
      "Actual: Negative\n",
      "Correct: True\n",
      "\n",
      "Input: The temperature today is 72 degrees.\n",
      "Predicted: Sentiment\n",
      "Actual: Neutral\n",
      "Correct: False\n",
      "\n",
      "Model Accuracy: 0.67\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model_func, test_cases):\n",
    "    '''\n",
    "    Evaluate the model on a set of test cases.\n",
    "\n",
    "    Args:\n",
    "    model_func: The function that makes predictions.\n",
    "    test_cases: A list of dictionaries, where each dictionary contains an \"input\" text and a \"label\" for the input.\n",
    "\n",
    "    Returns:\n",
    "    The accuracy of the model on the test cases. \n",
    "    '''\n",
    "    correct = 0\n",
    "    total = len(test_cases)\n",
    "    \n",
    "    for case in test_cases:\n",
    "        input_text = case['input']\n",
    "        true_label = case['label']\n",
    "        prediction = model_func(input_text).strip()\n",
    "        \n",
    "        is_correct = prediction.lower() == true_label.lower()\n",
    "        correct += int(is_correct)\n",
    "        \n",
    "        print(f\"Input: {input_text}\")\n",
    "        print(f\"Predicted: {prediction}\")\n",
    "        print(f\"Actual: {true_label}\")\n",
    "        print(f\"Correct: {is_correct}\\n\")\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    return accuracy\n",
    "\n",
    "test_cases = [\n",
    "    {\"input\": \"This product exceeded my expectations!\", \"label\": \"Positive\"},\n",
    "    {\"input\": \"I'm utterly disappointed with the service.\", \"label\": \"Negative\"},\n",
    "    {\"input\": \"The temperature today is 72 degrees.\", \"label\": \"Neutral\"}\n",
    "]\n",
    "\n",
    "accuracy = evaluate_model(few_shot_sentiment_classification, test_cases)\n",
    "print(f\"Model Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865d8c7c-6fa5-484d-bd94-8d3e99adb93c",
   "metadata": {},
   "source": [
    "# Basic Chain-of_Thoughts Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a794e581-3c96-46ce-8f66-7bb479a83ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Response:\n",
      "To find the average speed, divide the distance traveled (120 km) by the time taken (2 hours).\n",
      "\n",
      "Average speed = Distance / Time\n",
      "= 120 km / 2 hours\n",
      "= 60 km/h.\n",
      "\n",
      "Chain of Thought Response:\n",
      "Here's the solution:\n",
      "\n",
      "1. Distance traveled = 120 km\n",
      "2. Time taken = 2 hours\n",
      "3. Average speed = Total distance / Total time\n",
      "4. Average speed = 120 km / 2 hours\n",
      "5. Average speed = 60 km/h\n"
     ]
    }
   ],
   "source": [
    "# Standard prompt\n",
    "standard_prompt = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"Answer the following question concisely: {question}.\"\n",
    ")\n",
    "\n",
    "# Chain of Thought prompt\n",
    "cot_prompt = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"Answer the following question step by step concisely: {question}\"\n",
    ")\n",
    "\n",
    "# Create chains\n",
    "standard_chain = standard_prompt | llm\n",
    "cot_chain = cot_prompt | llm\n",
    "\n",
    "# Example question\n",
    "question = \"If a train travels 120 km in 2 hours, what is its average speed in km/h?\"\n",
    "\n",
    "# Get responses\n",
    "standard_response = standard_chain.invoke(question).content\n",
    "cot_response = cot_chain.invoke(question).content\n",
    "\n",
    "print(\"Standard Response:\")\n",
    "print(standard_response)\n",
    "print(\"\\nChain of Thought Response:\")\n",
    "print(cot_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ed502fcd-c193-4ab1-953a-78b6f4010579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's the step-by-step solution to the problem:\n",
      "\n",
      "**Step 1: State what we're going to calculate**\n",
      "We want to find the average speed for the entire journey.\n",
      "\n",
      "**Step 2: Write the formula we'll use (if applicable)**\n",
      "The formula for average speed is:\n",
      "\n",
      "Average Speed = Total Distance / Total Time\n",
      "\n",
      "Since we don't know the total time, we can also use the formula:\n",
      "\n",
      "Total Time = (Distance1 / Speed1) + (Distance2 / Speed2)\n",
      "\n",
      "**Step 3: Perform the calculation**\n",
      "\n",
      "First, let's calculate the time taken for each part of the journey:\n",
      "\n",
      "Time taken to travel 150 km at 60 km/h:\n",
      "Time = Distance / Speed\n",
      "= 150 km / 60 km/h\n",
      "= 2.5 hours\n",
      "\n",
      "Time taken to travel 100 km at 50 km/h:\n",
      "Time = Distance / Speed\n",
      "= 100 km / 50 km/h\n",
      "= 2 hours\n",
      "\n",
      "Now, let's calculate the total time:\n",
      "Total Time = (Distance1 / Speed1) + (Distance2 / Speed2)\n",
      "= (150 km / 60 km/h) + (100 km / 50 km/h)\n",
      "= 2.5 hours + 2 hours\n",
      "= 4.5 hours\n",
      "\n",
      "**Step 4: Explain the result**\n",
      "The total time taken for the entire journey is 4.5 hours, and the total distance traveled is 150 km + 100 km = 250 km.\n",
      "\n",
      "Now we can calculate the average speed:\n",
      "Average Speed = Total Distance / Total Time\n",
      "= 250 km / 4.5 hours\n",
      "= 55.56 km/h\n",
      "\n",
      "Therefore, the average speed for the entire journey is approximately 55.56 km/h.\n"
     ]
    }
   ],
   "source": [
    "advanced_cot_prompt = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"\"\"Solve the following problem step by step. For each step:\n",
    "1. State what you're going to calculate\n",
    "2. Write the formula you'll use (if applicable)\n",
    "3. Perform the calculation\n",
    "4. Explain the result\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Solution:\"\"\"\n",
    ")\n",
    "\n",
    "advanced_cot_chain = advanced_cot_prompt | llm\n",
    "\n",
    "complex_question = \"A car travels 150 km at 60 km/h, then another 100 km at 50 km/h. What is the average speed for the entire journey?\"\n",
    "\n",
    "advanced_cot_response = advanced_cot_chain.invoke(complex_question).content\n",
    "print(advanced_cot_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74606c6b-8c60-4a10-8d42-06d86a5fd23a",
   "metadata": {},
   "source": [
    "## Comparative Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1e4adff0-b9ff-40ca-89e8-ad4ec6a736c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Response:\n",
      "To find the time it takes for the tank to overflow, we need to calculate the volume of water in the tank and then divide that by the rate at which water is being added.\n",
      "\n",
      "The volume of a cylinder is given by V = πr^2h, where r is the radius and h is the height. \n",
      "\n",
      "First, let's find the total capacity of the tank:\n",
      "\n",
      "V = π(1.5)^2(4) \n",
      "= 3.14159 * 2.25 * 4\n",
      "≈ 28.27 cubic meters\n",
      "\n",
      "Since the tank is 2/3 full, we need to calculate the volume of water in the tank:\n",
      "\n",
      "Volume of water = (2/3) * 28.27 ≈ 18.755 cubic meters\n",
      "\n",
      "Now, let's convert this volume from cubic meters to liters:\n",
      "\n",
      "1 cubic meter = 1000 liters\n",
      "So, 18.755 cubic meters = 18,755 liters\n",
      "\n",
      "The rate at which water is being added is 10 liters per minute. To find the time it takes for the tank to overflow, we can divide the total volume of water by this rate:\n",
      "\n",
      "Time = Volume / Rate \n",
      "= 18,755 / 10\n",
      "≈ 1875 minutes \n",
      "\n",
      "Now, let's convert this time from minutes to hours and minutes:\n",
      "\n",
      "1875 minutes ≈ 31.25 hours\n",
      "\n",
      "So, it will take approximately 31 hours and 15 minutes for the tank to overflow.\n",
      "\n",
      "Chain of Thought Response:\n",
      "**Step 1: Calculate the volume of water in the tank**\n",
      "\n",
      "To find out how long it will take for the tank to overflow, we need to calculate the total volume of water that can be held in the tank. Since the tank is 2/3 full, we'll first calculate the total volume of the tank and then multiply it by 2/3.\n",
      "\n",
      "**Formula:** Volume = πr²h\n",
      "\n",
      "where r is the radius (1.5 meters) and h is the height (4 meters)\n",
      "\n",
      "**Calculation:**\n",
      "\n",
      "Volume = π × (1.5)² × 4\n",
      "= 3.14159 × 2.25 × 4\n",
      "= 28.274 cubic meters\n",
      "\n",
      "Since the tank is 2/3 full, we multiply the total volume by 2/3:\n",
      "\n",
      "Volume of water in tank = 28.274 × (2/3)\n",
      "= 18.748 cubic meters\n",
      "\n",
      "**Step 2: Convert the volume from cubic meters to liters**\n",
      "\n",
      "We know that 1000 liters = 1 cubic meter, so we can convert the volume from cubic meters to liters by multiplying by 1000:\n",
      "\n",
      "Volume of water in tank (in liters) = 18.748 × 1000\n",
      "= 18748 liters\n",
      "\n",
      "**Step 3: Calculate the time it will take for the tank to overflow**\n",
      "\n",
      "To find out how long it will take for the tank to overflow, we need to divide the total volume of the tank by the rate at which water is being added (10 liters per minute).\n",
      "\n",
      "Time = Total Volume / Rate\n",
      "= 18748 liters / 10 liters/minute\n",
      "= 1874.8 minutes\n",
      "\n",
      "**Step 4: Convert the time from minutes to hours and minutes**\n",
      "\n",
      "To convert the time from minutes to hours and minutes, we'll divide by 60 (since there are 60 minutes in an hour):\n",
      "\n",
      "Time = 1874.8 minutes / 60\n",
      "= 31.24 hours\n",
      "\n",
      "Rounding to the nearest minute, we get:\n",
      "\n",
      "Time ≈ 31 hours and 15 minutes\n"
     ]
    }
   ],
   "source": [
    "challenging_question = \"\"\"\n",
    "A cylindrical water tank with a radius of 1.5 meters and a height of 4 meters is 2/3 full. \n",
    "If water is being added at a rate of 10 liters per minute, how long will it take for the tank to overflow? \n",
    "Give your answer in hours and minutes, rounded to the nearest minute. \n",
    "(Use 3.14159 for π and 1000 liters = 1 cubic meter)\"\"\"\n",
    "\n",
    "standard_response = standard_chain.invoke(challenging_question).content\n",
    "cot_response = advanced_cot_chain.invoke(challenging_question).content\n",
    "\n",
    "print(\"Standard Response:\")\n",
    "print(standard_response)\n",
    "print(\"\\nChain of Thought Response:\")\n",
    "print(cot_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196df0d7-a394-457c-8457-e27be7dea92d",
   "metadata": {},
   "source": [
    "## Problem-Solving Applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f324b008-328f-4f4e-9bc5-2970f4d244ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**List the Facts:**\n",
      "\n",
      "1. There are three people in a room: Amy, Bob, and Charlie.\n",
      "2. One person always tells the truth, one always lies, and one alternates between truth and lies.\n",
      "3. Amy says, 'Bob is a liar.'\n",
      "4. Bob says, 'Charlie alternates between truth and lies.'\n",
      "5. Charlie says, 'Amy and I are both liars.'\n",
      "\n",
      "**Identify all the characters or elements involved:**\n",
      "\n",
      "1. Amy\n",
      "2. Bob\n",
      "3. Charlie\n",
      "\n",
      "**Possible Roles or Conditions:**\n",
      "\n",
      "1. Truth-teller (always tells the truth)\n",
      "2. Liar (always lies)\n",
      "3. Alternator (alternates between truth and lies)\n",
      "\n",
      "**Note the Constraints:**\n",
      "\n",
      "1. The statements made by each person must be consistent with their role.\n",
      "2. If Amy is a truth-teller, Bob cannot be a liar, as Amy's statement would be false.\n",
      "3. If Charlie is an alternator, his statement about Amy and himself being liars could be either true or false.\n",
      "\n",
      "**Generate Possible Scenarios:**\n",
      "\n",
      "1. Amy is the Truth-Teller:\n",
      "\t* Bob is the Liar\n",
      "\t* Charlie is the Alternator\n",
      "2. Amy is the Liar:\n",
      "\t* Bob is the Truth-Teller\n",
      "\t* Charlie is the Alternator\n",
      "3. Amy is the Alternator:\n",
      "\t* Bob is the Truth-Teller\n",
      "\t* Charlie is the Liar\n",
      "4. Bob is the Truth-Teller:\n",
      "\t* Amy is the Liar\n",
      "\t* Charlie is the Alternator\n",
      "5. Bob is the Liar:\n",
      "\t* Amy is the Truth-Teller\n",
      "\t* Charlie is the Alternator\n",
      "6. Bob is the Alternator:\n",
      "\t* Amy is the Truth-Teller\n",
      "\t* Charlie is the Liar\n",
      "7. Charlie is the Truth-Teller:\n",
      "\t* Amy is the Liar\n",
      "\t* Bob is the Alternator\n",
      "8. Charlie is the Liar:\n",
      "\t* Amy is the Truth-Teller\n",
      "\t* Bob is the Alternator\n",
      "9. Charlie is the Alternator:\n",
      "\t* Amy is the Truth-Teller\n",
      "\t* Bob is the Liar\n",
      "\n",
      "**Test Each Scenario:**\n",
      "\n",
      "1. Amy is the Truth-Teller:\n",
      "\t* If Amy says Bob is a liar, and Bob is indeed a liar, then Amy's statement is true.\n",
      "\t* However, if Charlie is an alternator, his statement about Amy and himself being liars could be false, which contradicts Amy's role as a truth-teller.\n",
      "2. Amy is the Liar:\n",
      "\t* If Amy says Bob is a liar, but Bob is actually a truth-teller, then Amy's statement is false, which aligns with her role as a liar.\n",
      "\t* However, if Charlie is an alternator, his statement about Amy and himself being liars could be true, which contradicts Amy's role as a liar.\n",
      "3. Amy is the Alternator:\n",
      "\t* If Amy says Bob is a liar, but Bob is actually a truth-teller, then Amy's statement is false, which aligns with her role as an alternator.\n",
      "\t* However, if Charlie is a liar, his statement about Amy and himself being liars could be true, which contradicts Amy's role as an alternator.\n",
      "4. Bob is the Truth-Teller:\n",
      "\t* If Bob says Charlie alternates between truth and lies, but Charlie is actually a truth-teller, then Bob's statement is false, which aligns with his role as a truth-teller.\n",
      "\t* However, if Amy is a liar, her statement about Bob being a liar could be true, which contradicts Bob's role as a truth-teller.\n",
      "5. Bob is the Liar:\n",
      "\t* If Bob says Charlie alternates between truth and lies, but Charlie is actually an alternator, then Bob's statement is false, which aligns with his role as a liar.\n",
      "\t* However, if Amy is a truth-teller, her statement about Bob being a liar could be true, which contradicts Bob's role as a liar.\n",
      "6. Bob is the Alternator:\n",
      "\t* If Bob says Charlie alternates between truth and lies, but Charlie is actually a truth-teller, then Bob's statement is false, which aligns with his role as an alternator.\n",
      "\t* However, if Amy is a truth-teller, her statement about Bob being a liar could be true, which contradicts Bob's role as an alternator.\n",
      "7. Charlie is the Truth-Teller:\n",
      "\t* If Charlie says Amy and he are both liars, but Amy is actually a truth-teller, then Charlie's statement is false, which aligns with his role as a truth-teller.\n",
      "\t* However, if Bob is a liar, his statement about Charlie being an alternator could be true, which contradicts Charlie's role as a truth-teller.\n",
      "8. Charlie is the Liar:\n",
      "\t* If Charlie says Amy and he are both liars, but Amy is actually a truth-teller, then Charlie's statement is false, which aligns with his role as a liar.\n",
      "\t* However, if Bob is an alternator, his statement about Charlie being an alternator could be true, which contradicts Charlie's role as a liar.\n",
      "9. Charlie is the Alternator:\n",
      "\t* If Charlie says Amy and he are both liars, but Amy is actually a truth-teller, then Charlie's statement is false, which aligns with his role as an alternator.\n",
      "\t* However, if Bob is a truth-teller, his statement about Charlie being an alternator could be true, which contradicts Charlie's role as an alternator.\n",
      "\n",
      "**Eliminate Inconsistent Scenarios:**\n",
      "\n",
      "1. Amy is the Truth-Teller:\n",
      "\t* Contradiction: If Amy says Bob is a liar and Bob is actually a truth-teller, then Amy's statement is false.\n",
      "2. Amy is the Liar:\n",
      "\t* Contradiction: If Charlie is an alternator, his statement about Amy and himself being liars could be true, which contradicts Amy's role as a liar.\n",
      "3. Amy is the Alternator:\n",
      "\t* Contradiction: If Charlie is a liar, his statement about Amy and himself being liars could be true, which contradicts Amy's role as an alternator.\n",
      "4. Bob is the Truth-Teller:\n",
      "\t* Contradiction: If Amy is a liar, her statement about Bob being a liar could be true, which contradicts Bob's role as a truth-teller.\n",
      "5. Bob is the Liar:\n",
      "\t* Contradiction: If Amy is a truth-teller, her statement about Bob being a liar could be false, which contradicts Bob's role as a liar.\n",
      "6. Bob is the Alternator:\n",
      "\t* Contradiction: If Amy is a truth-teller, her statement about Bob being a liar could be true, which contradicts Bob's role as an alternator.\n",
      "7. Charlie is the Truth-Teller:\n",
      "\t* Contradiction: If Bob is a liar, his statement about Charlie being an alternator could be true, which contradicts Charlie's role as a truth-teller.\n",
      "8. Charlie is the Liar:\n",
      "\t* Contradiction: If Amy is a truth-teller, her statement about Amy and herself being liars could be false, which contradicts Charlie's role as a liar.\n",
      "9. Charlie is the Alternator:\n",
      "\t* Contradiction: If Bob is a truth-teller, his statement about Charlie being an alternator could be true, which contradicts Charlie's role as an alternator.\n",
      "\n",
      "**Conclude the Solution:**\n",
      "\n",
      "The only consistent scenario is:\n",
      "\n",
      "1. Amy is the Liar\n",
      "2. Bob is the Alternator\n",
      "3. Charlie is the Truth-Teller\n",
      "\n",
      "Explanation:\n",
      "Amy says Bob is a liar, but since Bob is actually an alternator, his statement about himself being a liar could be true, which aligns with Amy's role as a liar.\n",
      "Bob says Charlie alternates between truth and lies, but since Charlie is actually a truth-teller, Bob's statement is false, which aligns with his role as an alternator.\n",
      "Charlie says Amy and he are both liars, but since Amy is actually a truth-teller, Charlie's statement is false, which aligns with his role as a truth-teller.\n",
      "\n",
      "This solution satisfies all the constraints and statements made by each person.\n"
     ]
    }
   ],
   "source": [
    "logical_reasoning_prompt = PromptTemplate(\n",
    "    input_variables=[\"scenario\"],\n",
    "    template=\"\"\"Analyze the following logical puzzle thoroughly. Follow these steps in your analysis:\n",
    "\n",
    "List the Facts:\n",
    "\n",
    "Summarize all the given information and statements clearly.\n",
    "Identify all the characters or elements involved.\n",
    "Identify Possible Roles or Conditions:\n",
    "\n",
    "Determine all possible roles, behaviors, or states applicable to the characters or elements (e.g., truth-teller, liar, alternator).\n",
    "Note the Constraints:\n",
    "\n",
    "Outline any rules, constraints, or relationships specified in the puzzle.\n",
    "Generate Possible Scenarios:\n",
    "\n",
    "Systematically consider all possible combinations of roles or conditions for the characters or elements.\n",
    "Ensure that all permutations are accounted for.\n",
    "Test Each Scenario:\n",
    "\n",
    "For each possible scenario:\n",
    "Assume the roles or conditions you've assigned.\n",
    "Analyze each statement based on these assumptions.\n",
    "Check for consistency or contradictions within the scenario.\n",
    "Eliminate Inconsistent Scenarios:\n",
    "\n",
    "Discard any scenarios that lead to contradictions or violate the constraints.\n",
    "Keep track of the reasoning for eliminating each scenario.\n",
    "Conclude the Solution:\n",
    "\n",
    "Identify the scenario(s) that remain consistent after testing.\n",
    "Summarize the findings.\n",
    "Provide a Clear Answer:\n",
    "\n",
    "State definitively the role or condition of each character or element.\n",
    "Explain why this is the only possible solution based on your analysis.\n",
    "Scenario:\n",
    "\n",
    "{scenario}\n",
    "\n",
    "Analysis:\"\"\")\n",
    "\n",
    "logical_reasoning_chain = logical_reasoning_prompt | llm\n",
    "\n",
    "logical_puzzle = \"\"\"In a room, there are three people: Amy, Bob, and Charlie. \n",
    "One of them always tells the truth, one always lies, and one alternates between truth and lies. \n",
    "Amy says, 'Bob is a liar.' \n",
    "Bob says, 'Charlie alternates between truth and lies.' \n",
    "Charlie says, 'Amy and I are both liars.' \n",
    "Determine the nature (truth-teller, liar, or alternator) of each person.\"\"\"\n",
    "\n",
    "logical_reasoning_response = logical_reasoning_chain.invoke(logical_puzzle).content\n",
    "print(logical_reasoning_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f71fe13-8e66-4a21-b6d1-324966bc3a74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
