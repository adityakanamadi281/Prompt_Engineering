{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4eec7251-c319-451b-b12c-2addc5a595a0",
   "metadata": {},
   "source": [
    "## Prompt Engineering Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ac74dcaa-36ac-40ce-9263-cb0a6953f7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c3e2f7e-4f64-4b9f-8d2c-035eb7e78f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11d9e8c9-bf49-43b7-9ca5-c8d645735e02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'Ollama is running'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.get(\"http://localhost:11434\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7559540-fcaf-4821-81fa-0bd5da0e8c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "OLLAMA_BASE_URL = \"http://localhost:11434/v1\"\n",
    "\n",
    "ollama = OpenAI(base_url=OLLAMA_BASE_URL, api_key='ollama')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8288acee-5e74-4237-bf88-7c754f7ee446",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"llama3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a77f424-d5a2-4a36-be33-ca950e58d758",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_prompt = \"Explain the concept of prompt engineering in one sentence.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd9ef067-2fed-46db-9d36-7fe0322109c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt engineering is the process of designing and optimizing the input text, known as a prompt, that feeds into language models like AI chatbots or natural language processing (NLP) systems to elicit specific, accurate, and relevant outputs from those models.\n"
     ]
    }
   ],
   "source": [
    "response = ollama.chat.completions.create(\n",
    "    model=model_name,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": basic_prompt}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3fd829aa-b808-41c4-89af-d7fe573a49b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Definition:** Prompt Engineering is the process of designing, crafting, and optimizing text prompts to elicit specific responses from language models, such as chatbots, virtual assistants, or other AI systems. The goal of prompt engineering is to maximize the accuracy, relevance, and coherence of the generated output while minimizing errors, ambiguities, and irrelevant information.\n",
      "\n",
      "**Importance:** Prompt engineering is crucial in various applications where natural language processing (NLP) and machine learning are used, such as:\n",
      "\n",
      "1. Customer service chatbots: To provide accurate and helpful responses to customer inquiries.\n",
      "2. Virtual assistants: To enable users to access information, perform tasks, or make requests more efficiently.\n",
      "3. Content generation: To produce high-quality content, such as articles, social media posts, or product descriptions.\n",
      "\n",
      "**Three Key Benefits of Prompt Engineering:**\n",
      "\n",
      "1. **Improved Accuracy and Relevance**: Well-crafted prompts can significantly reduce errors and irrelevant responses, leading to more accurate and relevant output. This is particularly important in applications where accuracy matters, such as customer service or medical diagnosis.\n",
      "2. **Increased Efficiency**: Optimized prompts can help language models process queries faster and more efficiently, reducing the time it takes to generate a response. This can lead to improved user experience and increased productivity in applications like virtual assistants or content generation.\n",
      "3. **Enhanced User Experience**: By providing clear, concise, and relevant prompts, prompt engineering can improve the overall user experience in various applications. For example, a well-designed prompt for a customer service chatbot can help users quickly find the information they need, reducing frustration and increasing satisfaction.\n",
      "\n",
      "By applying the principles of prompt engineering, developers and designers can create more effective language models that provide better outcomes for users and organizations alike.\n"
     ]
    }
   ],
   "source": [
    "topic = \"prompt engineering\"\n",
    "\n",
    "structured_prompt = f\"\"\"\n",
    "Provide a definition of {topic}, explain its importance, and list three key benefits.\n",
    "\"\"\"\n",
    "\n",
    "response = ollama.chat.completions.create(\n",
    "    model=model_name,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": structured_prompt}\n",
    "    ],\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "output = response.choices[0].message.content\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "494696a0-d7b4-4029-a5f6-c542eb35d0d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The statement is completely incorrect. The capital of France is actually Paris, not London. London is the capital city of England, which is part of the United Kingdom (UK).\n"
     ]
    }
   ],
   "source": [
    "statement = \"The capital of France is London.\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Evaluate the following statement for factual accuracy.\n",
    "If it's incorrect, provide the correct information.\n",
    "\n",
    "Statement: {statement}\n",
    "Evaluation:\n",
    "\"\"\"\n",
    "\n",
    "response = ollama.chat.completions.create(\n",
    "    model=\"llama3.2\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1cbed897-ac6c-4ff8-adf5-8e964b002826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To calculate the compound interest, we can use the formula:\n",
      "\n",
      "A = P(1 + r/n)^(nt)\n",
      "\n",
      "Where:\n",
      "A = final amount\n",
      "P = principal (initial investment) = $1000\n",
      "r = annual interest rate = 5% = 0.05\n",
      "n = number of times interest is compounded per year = 1 (compounded annually)\n",
      "t = time in years = 5\n",
      "\n",
      "First, we need to calculate the total amount after 5 years:\n",
      "\n",
      "A = 1000(1 + 0.05/1)^(1*5)\n",
      "A = 1000(1 + 0.05)^5\n",
      "A = 1000(1.05)^5\n",
      "A = 1000 * 1.2762815625\n",
      "A = 1276.28\n",
      "\n",
      "Now, we can calculate the compound interest:\n",
      "\n",
      "Compound Interest = A - P\n",
      "= 1276.28 - 1000\n",
      "= 276.28\n"
     ]
    }
   ],
   "source": [
    "problem = \"Calculate the compound interest on $1000 invested for 5 years at an annual rate of 5%, compounded annually.\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Solve the following problem step by step:\n",
    "\n",
    "Problem: {problem}\n",
    "\n",
    "Solution:\n",
    "1)\n",
    "\"\"\"\n",
    "\n",
    "response = ollama.chat.completions.create(\n",
    "    model=\"llama3.2\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ad6f2e-e94b-4592-954d-3e90c1b3a2b2",
   "metadata": {},
   "source": [
    "## Using Langchain PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2b815cfc-3b60-4302-91ed-33b01e602c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Definition of Prompt Engineering:**\n",
      "\n",
      "Prompt engineering is the process of crafting high-quality input prompts to elicit specific responses from language models, artificial intelligence (AI) systems, or other forms of machine learning. The goal of prompt engineering is to optimize the performance of a model by selecting the most effective and informative inputs that lead to accurate, relevant, and contextually appropriate outputs.\n",
      "\n",
      "**Importance of Prompt Engineering:**\n",
      "\n",
      "Prompt engineering plays a crucial role in enhancing the performance and reliability of AI systems. By carefully designing and crafting prompts, developers can improve the quality of models' responses, increase their accuracy, and reduce errors. Effective prompt engineering is essential for:\n",
      "\n",
      "1. Improving model performance: Well-designed prompts can help models understand the context and intent behind user queries, leading to more accurate and relevant responses.\n",
      "2. Enhancing user experience: Prompt engineering ensures that AI systems provide users with helpful and informative outputs, which enhances their overall experience and trust in the system.\n",
      "3. Reducing bias and errors: By carefully crafting prompts, developers can minimize biases and errors in model outputs, ensuring that AI systems provide fair and accurate results.\n",
      "\n",
      "**Three Key Benefits of Prompt Engineering:**\n",
      "\n",
      "1. **Improved Response Accuracy**: Well-designed prompts can lead to more accurate responses from language models, reducing errors and improving overall performance.\n",
      "2. **Increased Model Reliability**: Prompt engineering helps ensure that AI systems are reliable and consistent in their outputs, which is critical for applications such as customer service, healthcare, and finance.\n",
      "3. **Enhanced User Engagement**: By providing users with high-quality and relevant responses to their queries, prompt engineering can increase user engagement and trust in AI-powered systems, leading to better adoption rates and long-term success.\n",
      "\n",
      "In summary, prompt engineering is a critical aspect of AI development that involves crafting effective input prompts to elicit specific responses from language models. Its importance lies in enhancing model performance, improving user experience, and reducing errors. By understanding the key benefits of prompt engineering, developers can optimize their models for better results and create more effective AI systems.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "llm = ChatOllama(model=\"llama3.2\")\n",
    "\n",
    "structured_prompt = PromptTemplate(\n",
    "    input_variables=[\"topic\"],\n",
    "    template=\"Provide a definition of {topic}, explain its importance, and list three key benefits.\"\n",
    ")\n",
    "\n",
    "chain = structured_prompt | llm\n",
    "\n",
    "output = chain.invoke({\"topic\": \"prompt engineering\"}).content\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bce4154d-4532-4c83-b4c3-0e36b235ecf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The statement is entirely incorrect. The capital of France is actually Paris, not London. London is the capital city of England, which is a part of the United Kingdom (UK).\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "# LLM\n",
    "llm = ChatOllama(model=\"llama3.2\")\n",
    "\n",
    "# Prompt\n",
    "fact_check_prompt = PromptTemplate(\n",
    "    input_variables=[\"statement\"],\n",
    "    template=\"\"\"Evaluate the following statement for factual accuracy.\n",
    "If it's incorrect, provide the correct information.\n",
    "\n",
    "Statement: {statement}\n",
    "Evaluation:\"\"\"\n",
    ")\n",
    "\n",
    "# Chain\n",
    "chain = fact_check_prompt | llm\n",
    "\n",
    "# Invoke\n",
    "response = chain.invoke({\"statement\": \"The capital of France is London.\"})\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "02b59873-ee49-4904-bd43-4a5600431463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To calculate the compound interest, we'll follow these steps:\n",
      "\n",
      "Step 1: Convert the annual interest rate to a decimal\n",
      "Annual interest rate = 5%\n",
      "Interest rate as a decimal = 0.05\n",
      "\n",
      "Step 2: Determine the number of compounding periods (years)\n",
      "Number of compounding periods = 5 years\n",
      "\n",
      "Step 3: Calculate the amount after 5 years using the compound interest formula:\n",
      "\n",
      "A = P x (1 + r)^n\n",
      "\n",
      "Where:\n",
      "A = final amount\n",
      "P = principal (initial investment) = $1000\n",
      "r = annual interest rate as a decimal = 0.05\n",
      "n = number of compounding periods = 5 years\n",
      "\n",
      "Step 4: Plug in the values and calculate:\n",
      "\n",
      "A = 1000 x (1 + 0.05)^5\n",
      "= 1000 x (1.05)^5\n",
      "= 1000 x 1.2762815625\n",
      "= 1276.28\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "# LLM\n",
    "llm = ChatOllama(model=\"llama3.2\")\n",
    "\n",
    "# Prompt\n",
    "problem_solving_prompt = PromptTemplate(\n",
    "    input_variables=[\"problem\"],\n",
    "    template=\"\"\"Solve the following problem step by step:\n",
    "\n",
    "Problem: {problem}\n",
    "\n",
    "Solution:\n",
    "1)\"\"\"\n",
    ")\n",
    "\n",
    "# Chain\n",
    "chain = problem_solving_prompt | llm\n",
    "\n",
    "# Run\n",
    "response = chain.invoke({\n",
    "    \"problem\": \"Calculate the compound interest on $1000 invested for 5 years at an annual rate of 5%, compounded annually.\"\n",
    "})\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dac26f-0966-43d1-9fd4-beb1588df3a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
